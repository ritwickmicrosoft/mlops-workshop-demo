{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c074d54",
   "metadata": {},
   "source": [
    "# 01 â€” Azure ML + MLflow Quickstart\n",
    "\n",
    "This notebook connects to an Azure ML workspace, sets MLflow tracking to the workspace, trains a simple model, logs metrics + artifacts, registers the model, and runs batch scoring.\n",
    "\n",
    "## Prereqs\n",
    "- Azure subscription + access to the workshop resource group\n",
    "- Azure ML workspace deployed (see `infra/main.bicep`)\n",
    "- Auth: `DefaultAzureCredential` (recommended) or interactive browser fallback\n",
    "\n",
    "## Known Issue: NumPy 2.x Compatibility\n",
    "MLflow embeds conda/pip dependencies when logging a model. If logged with NumPy 2.x, Azure ML's curated environments (NumPy 1.x) will fail. This notebook explicitly pins `numpy<2.0` when logging the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca183a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if needed)\n",
    "# %pip install -r ../requirements.txt\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import sys\n",
    "import site\n",
    "\n",
    "# Avoid mixing user-site packages with the repo venv\n",
    "try:\n",
    "    user_site = site.getusersitepackages()\n",
    "    sys.path = [p for p in sys.path if os.path.normcase(p) != os.path.normcase(user_site)]\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.entities import Model, ManagedOnlineEndpoint, ManagedOnlineDeployment\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "print('Imports OK')\n",
    "print('Python:', sys.executable)\n",
    "print('mlflow:', mlflow.__version__, 'from', mlflow.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119f8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workshop configuration\n",
    "import subprocess\n",
    "import shutil\n",
    "import platform\n",
    "\n",
    "def _get_windows_persisted_env(var_name: str) -> str:\n",
    "    \"\"\"Read a persisted env var from Windows registry (HKCU/HKLM).\"\"\"\n",
    "    try:\n",
    "        import winreg\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "    for root, path in (\n",
    "        (winreg.HKEY_CURRENT_USER, r\"Environment\"),\n",
    "        (winreg.HKEY_LOCAL_MACHINE, r\"SYSTEM\\CurrentControlSet\\Control\\Session Manager\\Environment\"),\n",
    "    ):\n",
    "        try:\n",
    "            with winreg.OpenKey(root, path) as key:\n",
    "                value, _ = winreg.QueryValueEx(key, var_name)\n",
    "                if isinstance(value, str) and value.strip():\n",
    "                    return value.strip()\n",
    "        except (FileNotFoundError, OSError):\n",
    "            continue\n",
    "    return \"\"\n",
    "\n",
    "SUBSCRIPTION_ID = os.getenv('AZURE_SUBSCRIPTION_ID', '').strip()\n",
    "RESOURCE_GROUP = os.getenv('AZURE_RESOURCE_GROUP', 'rg-dnd-mlops-demo').strip()\n",
    "WORKSPACE_NAME = os.getenv('AZURE_ML_WORKSPACE', 'mlw-dndmlops2-dev').strip()\n",
    "\n",
    "# Windows: try loading from registry if env var not set\n",
    "if not SUBSCRIPTION_ID and platform.system() == 'Windows':\n",
    "    persisted = _get_windows_persisted_env('AZURE_SUBSCRIPTION_ID')\n",
    "    if persisted:\n",
    "        SUBSCRIPTION_ID = persisted\n",
    "        os.environ['AZURE_SUBSCRIPTION_ID'] = SUBSCRIPTION_ID\n",
    "        print('Loaded AZURE_SUBSCRIPTION_ID from Windows registry.')\n",
    "\n",
    "# Fallback: Azure CLI\n",
    "if not SUBSCRIPTION_ID and shutil.which('az'):\n",
    "    try:\n",
    "        SUBSCRIPTION_ID = subprocess.check_output(\n",
    "            ['az', 'account', 'show', '--query', 'id', '-o', 'tsv'],\n",
    "            text=True, stderr=subprocess.STDOUT,\n",
    "        ).strip()\n",
    "        if SUBSCRIPTION_ID:\n",
    "            os.environ['AZURE_SUBSCRIPTION_ID'] = SUBSCRIPTION_ID\n",
    "            print('Using subscription from Azure CLI (az account show).')\n",
    "    except Exception as e:\n",
    "        print('Azure CLI fallback failed:', repr(e))\n",
    "\n",
    "if not SUBSCRIPTION_ID:\n",
    "    raise ValueError('Missing AZURE_SUBSCRIPTION_ID. Set it as an env var or update this cell.')\n",
    "\n",
    "print('Subscription:', SUBSCRIPTION_ID)\n",
    "print('Resource group:', RESOURCE_GROUP)\n",
    "print('Workspace:', WORKSPACE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2345ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate and connect to Azure ML\n",
    "try:\n",
    "    credential = DefaultAzureCredential(exclude_interactive_browser_credential=True)\n",
    "    credential.get_token('https://management.azure.com/.default')\n",
    "except Exception:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=SUBSCRIPTION_ID,\n",
    "    resource_group_name=RESOURCE_GROUP,\n",
    "    workspace_name=WORKSPACE_NAME,\n",
    ")\n",
    "\n",
    "print('Connected to workspace:', ml_client.workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8362a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure MLflow to use Azure ML workspace tracking\n",
    "tracking_uri = ml_client.workspaces.get(WORKSPACE_NAME).mlflow_tracking_uri\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "experiment_name = os.getenv('MLFLOW_EXPERIMENT_NAME', 'mlops-hackathon-demo')\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print('MLflow tracking URI:', tracking_uri)\n",
    "print('Experiment:', experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979994e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (OpenML Spambase - 4,601 emails, 57 features)\n",
    "print('Loading Spambase dataset from OpenML...')\n",
    "spambase = fetch_openml(data_id=44, as_frame=True, parser='auto')\n",
    "data = spambase.frame.rename(columns={'class': 'is_spam'})\n",
    "data['is_spam'] = data['is_spam'].astype(int)\n",
    "\n",
    "X = data.drop('is_spam', axis=1)\n",
    "y = data['is_spam']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print('Train:', X_train.shape, 'Test:', X_test.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4da461d",
   "metadata": {},
   "source": [
    "## Train Model with MLflow Tracking\n",
    "\n",
    "We train a RandomForest classifier and log:\n",
    "- Parameters\n",
    "- Metrics (accuracy, precision, recall, F1, AUC)\n",
    "- Feature importance artifact\n",
    "- Model with **explicit `numpy<2.0`** requirement for Azure ML compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac60bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models import infer_signature\n",
    "\n",
    "params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'random_state': 42,\n",
    "}\n",
    "\n",
    "# Explicit pip requirements for Azure ML compatibility\n",
    "pip_requirements = [\n",
    "    'numpy<2.0',\n",
    "    'scikit-learn>=1.0,<2.0',\n",
    "    'pandas',\n",
    "    'mlflow',\n",
    "]\n",
    "\n",
    "with mlflow.start_run(run_name='spam-classifier-rf') as run:\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param('training_samples', len(X_train))\n",
    "    mlflow.log_param('dataset', 'UCI Spambase')\n",
    "    mlflow.log_param('numpy_constraint', '<2.0')\n",
    "\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_pred_proba),\n",
    "    }\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    feature_importance = (\n",
    "        pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_})\n",
    "        .sort_values('importance', ascending=False)\n",
    "    )\n",
    "    feature_importance.to_csv('feature_importance.csv', index=False)\n",
    "    mlflow.log_artifact('feature_importance.csv')\n",
    "\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        model,\n",
    "        artifact_path='model',\n",
    "        signature=signature,\n",
    "        pip_requirements=pip_requirements,\n",
    "        registered_model_name='spam-classifier',\n",
    "    )\n",
    "\n",
    "print('Run ID:', run.info.run_id)\n",
    "print('Metrics:', {k: round(v, 4) for k, v in metrics.items()})\n",
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf6a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register model in Azure ML with governance metadata\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "model_uri = f'runs:/{run.info.run_id}/model'\n",
    "\n",
    "registered_model = ml_client.models.create_or_update(\n",
    "    Model(\n",
    "        path=model_uri,\n",
    "        name='spam-classifier',\n",
    "        type=AssetTypes.MLFLOW_MODEL,\n",
    "        description='Email spam classifier (numpy<2.0 compatible)',\n",
    "        tags={\n",
    "            'author': os.getenv('MODEL_AUTHOR', 'workshop-attendee'),\n",
    "            'use_case': 'spam_detection',\n",
    "            'dataset': 'UCI Spambase',\n",
    "            'framework': 'sklearn',\n",
    "            'numpy_constraint': '<2.0',\n",
    "        },\n",
    "        properties={k: str(round(v, 4)) for k, v in metrics.items()},\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f'Model registered: {registered_model.name}:{registered_model.version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25b58d8",
   "metadata": {},
   "source": [
    "---\n",
    "## Batch Scoring Job\n",
    "\n",
    "Run **asynchronous batch scoring** as an Azure ML command job:\n",
    "- No online endpoint required\n",
    "- Produces a CSV output you can download\n",
    "- Uses the registered MLflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6d9ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch scoring (1/3): resolve the model reference\n",
    "from typing import Optional\n",
    "from azure.ai.ml import Input, Output, command\n",
    "\n",
    "model_name = registered_model.name\n",
    "model_version = str(registered_model.version)\n",
    "model_ref = f'azureml:{model_name}:{model_version}'\n",
    "\n",
    "batch_n_rows = int(os.getenv('BATCH_N_ROWS', '100'))\n",
    "\n",
    "print('Model reference:', model_ref)\n",
    "print('Batch rows:', batch_n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f09130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch scoring (2/3): submit job\n",
    "from azure.ai.ml.entities import UserIdentityConfiguration\n",
    "\n",
    "# Auto-select compute\n",
    "batch_compute = os.getenv('AML_BATCH_COMPUTE', '').strip()\n",
    "if not batch_compute:\n",
    "    computes = list(ml_client.compute.list())\n",
    "    aml_compute_names = [\n",
    "        getattr(c, 'name', None) for c in computes\n",
    "        if getattr(c, 'name', None)\n",
    "        and ('amlcompute' in str(getattr(c, 'type', '')).lower())\n",
    "    ]\n",
    "    if not aml_compute_names:\n",
    "        raise RuntimeError('No AmlCompute cluster found. Create one in Azure ML Studio.')\n",
    "    batch_compute = aml_compute_names[0]\n",
    "    print('Auto-selected compute:', batch_compute)\n",
    "else:\n",
    "    print('Using compute:', batch_compute)\n",
    "\n",
    "batch_env = 'azureml://registries/azureml/environments/sklearn-1.5/labels/latest'\n",
    "\n",
    "inline_command = f\"\"\"python - <<'PYSCRIPT'\n",
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "model_dir = r\"${{{{inputs.model}}}}\"\n",
    "out_dir = r\"${{{{outputs.predictions}}}}\"\n",
    "n_rows = {batch_n_rows}\n",
    "\n",
    "spambase = fetch_openml(data_id=44, as_frame=True, parser='auto')\n",
    "data = spambase.frame.rename(columns={{'class': 'is_spam'}})\n",
    "X = data.drop('is_spam', axis=1).head(n_rows)\n",
    "\n",
    "model = mlflow.pyfunc.load_model(model_dir)\n",
    "preds = model.predict(X)\n",
    "\n",
    "out = pd.DataFrame({{'prediction': preds}})\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_path = os.path.join(out_dir, 'predictions.csv')\n",
    "out.to_csv(out_path, index=False)\n",
    "print('Wrote:', out_path)\n",
    "PYSCRIPT\n",
    "\"\"\"\n",
    "\n",
    "batch_job = command(\n",
    "    command=inline_command,\n",
    "    inputs={'model': Input(type='mlflow_model', path=model_ref, mode='download')},\n",
    "    outputs={'predictions': Output(type='uri_folder')},\n",
    "    environment=batch_env,\n",
    "    compute=batch_compute,\n",
    "    experiment_name=experiment_name,\n",
    "    display_name='batch-score-spam-classifier',\n",
    "    identity=UserIdentityConfiguration(),\n",
    ")\n",
    "\n",
    "submitted = ml_client.jobs.create_or_update(batch_job)\n",
    "print('Submitted batch scoring job:', submitted.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8971e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch scoring (3/3): wait + download output\n",
    "from pathlib import Path\n",
    "\n",
    "wait_seconds = int(os.getenv('BATCH_WAIT_SECONDS', '900'))\n",
    "poll_seconds = 15\n",
    "\n",
    "start = time.time()\n",
    "status = None\n",
    "while True:\n",
    "    status = ml_client.jobs.get(submitted.name).status\n",
    "    print('Job status:', status)\n",
    "    if status in {'Completed', 'Failed', 'Canceled'}:\n",
    "        break\n",
    "    if time.time() - start > wait_seconds:\n",
    "        print('Job still running; re-run this cell later.')\n",
    "        break\n",
    "    time.sleep(poll_seconds)\n",
    "\n",
    "if status == 'Completed':\n",
    "    download_dir = Path('batch_outputs') / submitted.name\n",
    "    download_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ml_client.jobs.download(name=submitted.name, download_path=str(download_dir), output_name='predictions')\n",
    "    print('Downloaded to:', download_dir.resolve())\n",
    "\n",
    "    pred_path = download_dir / 'named-outputs' / 'predictions' / 'predictions.csv'\n",
    "    if pred_path.exists():\n",
    "        preds = pd.read_csv(pred_path)\n",
    "        display(preds.head(10))\n",
    "    else:\n",
    "        print('Predictions file not found. Check Studio for job output.')\n",
    "elif status == 'Failed':\n",
    "    print('Job failed. Check logs in Azure ML Studio.')\n",
    "    try:\n",
    "        ml_client.jobs.stream(submitted.name)\n",
    "    except Exception as e:\n",
    "        print('Could not stream logs:', repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07ba16",
   "metadata": {},
   "source": [
    "---\n",
    "## Batch Endpoint (Production Pattern)\n",
    "\n",
    "A **Batch Endpoint** provides a durable REST endpoint for batch inference:\n",
    "- No always-on compute (cost-efficient)\n",
    "- Versioned deployments with traffic routing\n",
    "- Built-in job management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Endpoint (1/3): Create the endpoint\n",
    "from azure.ai.ml.entities import BatchEndpoint\n",
    "\n",
    "batch_endpoint_name = os.getenv('AML_BATCH_ENDPOINT_NAME', f'spam-batch-{uuid.uuid4().hex[:8]}')\n",
    "\n",
    "batch_endpoint = BatchEndpoint(\n",
    "    name=batch_endpoint_name,\n",
    "    description='Spam classifier batch endpoint',\n",
    "    tags={'environment': 'workshop'},\n",
    ")\n",
    "\n",
    "print(f'Creating batch endpoint: {batch_endpoint_name}')\n",
    "ml_client.batch_endpoints.begin_create_or_update(batch_endpoint).result()\n",
    "print('Batch endpoint created!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06de4138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Endpoint (2/3): Create deployment\n",
    "from azure.ai.ml.entities import ModelBatchDeployment, ModelBatchDeploymentSettings\n",
    "from azure.ai.ml.constants import BatchDeploymentOutputAction\n",
    "from azure.ai.ml.entities import BatchRetrySettings\n",
    "\n",
    "model_for_batch = f'azureml:{registered_model.name}:{registered_model.version}'\n",
    "batch_endpoint_env = 'azureml://registries/azureml/environments/sklearn-1.5/labels/latest'\n",
    "deployment_name = 'numpy1x'\n",
    "\n",
    "batch_deployment = ModelBatchDeployment(\n",
    "    name=deployment_name,\n",
    "    endpoint_name=batch_endpoint_name,\n",
    "    model=model_for_batch,\n",
    "    environment=batch_endpoint_env,\n",
    "    compute=batch_compute,\n",
    "    settings=ModelBatchDeploymentSettings(\n",
    "        instance_count=1,\n",
    "        max_concurrency_per_instance=2,\n",
    "        mini_batch_size=10,\n",
    "        output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
    "        output_file_name='predictions.csv',\n",
    "        retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n",
    "        logging_level='info',\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f'Creating deployment: {deployment_name}')\n",
    "ml_client.batch_deployments.begin_create_or_update(batch_deployment).result()\n",
    "\n",
    "# Set as default\n",
    "batch_endpoint = ml_client.batch_endpoints.get(batch_endpoint_name)\n",
    "batch_endpoint.defaults.deployment_name = deployment_name\n",
    "ml_client.batch_endpoints.begin_create_or_update(batch_endpoint).result()\n",
    "\n",
    "print(f'Deployment \"{deployment_name}\" created and set as default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae8d178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Endpoint (3/3): Invoke with test data\n",
    "from azure.ai.ml import Input\n",
    "from pathlib import Path\n",
    "\n",
    "batch_input_path = Path('batch_endpoint_input.csv')\n",
    "X_test.head(50).to_csv(batch_input_path, index=False)\n",
    "print(f'Created input file: {batch_input_path} (50 rows)')\n",
    "\n",
    "job = ml_client.batch_endpoints.invoke(\n",
    "    endpoint_name=batch_endpoint_name,\n",
    "    inputs={'input': Input(path=str(batch_input_path.resolve()), type=AssetTypes.URI_FILE)},\n",
    ")\n",
    "\n",
    "print(f'Batch job submitted: {job.name}')\n",
    "print(f'Monitor: https://ml.azure.com/runs/{job.name}?wsid=/subscriptions/{SUBSCRIPTION_ID}/resourcegroups/{RESOURCE_GROUP}/workspaces/{WORKSPACE_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d13905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for batch endpoint job and download results\n",
    "job_name = job.name\n",
    "wait_seconds = 600\n",
    "\n",
    "start = time.time()\n",
    "while True:\n",
    "    job_status = ml_client.jobs.get(job_name)\n",
    "    status = job_status.status\n",
    "    print(f'Batch job status: {status}')\n",
    "    if status in {'Completed', 'Failed', 'Canceled'}:\n",
    "        break\n",
    "    if time.time() - start > wait_seconds:\n",
    "        print('Job still running. Re-run later.')\n",
    "        break\n",
    "    time.sleep(15)\n",
    "\n",
    "if status == 'Completed':\n",
    "    output_dir = Path('batch_endpoint_outputs') / job_name\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ml_client.jobs.download(name=job_name, download_path=str(output_dir), output_name='score')\n",
    "    print(f'Downloaded to: {output_dir}')\n",
    "\n",
    "    for pred_file in output_dir.rglob('predictions.csv'):\n",
    "        preds_df = pd.read_csv(pred_file)\n",
    "        print(f'\\nPredictions from {pred_file}:')\n",
    "        display(preds_df.head(10))\n",
    "        break\n",
    "else:\n",
    "    print(f'Job status: {status}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4101b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Get batch endpoint details\n",
    "endpoint_info = ml_client.batch_endpoints.get(batch_endpoint_name)\n",
    "\n",
    "print('=== Batch Endpoint Details ===')\n",
    "print(f'Name: {endpoint_info.name}')\n",
    "print(f'Scoring URI: {endpoint_info.scoring_uri}')\n",
    "print(f'Default deployment: {endpoint_info.defaults.deployment_name}')\n",
    "print(f'Studio: https://ml.azure.com/batchEndpoints/{batch_endpoint_name}?wsid=/subscriptions/{SUBSCRIPTION_ID}/resourcegroups/{RESOURCE_GROUP}/workspaces/{WORKSPACE_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d767b9f",
   "metadata": {},
   "source": [
    "---\n",
    "## Optional: Real-time Serving (Managed Online Endpoint)\n",
    "\n",
    "Deploy a **managed online endpoint** for real-time inference.\n",
    "- Takes 5-10 minutes to provision\n",
    "- Requires VM quota for the chosen instance type\n",
    "\n",
    "Skip this section if batch scoring meets your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06748f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and deploy managed online endpoint\n",
    "online_endpoint_name = os.getenv('AML_ENDPOINT_NAME', f'spam-clf-{uuid.uuid4().hex[:8]}')\n",
    "\n",
    "online_endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description='Spam classification endpoint',\n",
    "    auth_mode='key',\n",
    "    tags={'environment': 'workshop'},\n",
    ")\n",
    "\n",
    "print(f'Creating endpoint: {online_endpoint_name}')\n",
    "ml_client.online_endpoints.begin_create_or_update(online_endpoint).result()\n",
    "print('Endpoint created!')\n",
    "\n",
    "online_deployment = ManagedOnlineDeployment(\n",
    "    name='blue',\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=f'azureml:{registered_model.name}:{registered_model.version}',\n",
    "    instance_type='Standard_DS3_v2',\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "print('Creating deployment (5-10 min)...')\n",
    "ml_client.online_deployments.begin_create_or_update(online_deployment).result()\n",
    "\n",
    "online_endpoint = ml_client.online_endpoints.get(online_endpoint_name)\n",
    "online_endpoint.traffic = {'blue': 100}\n",
    "ml_client.online_endpoints.begin_create_or_update(online_endpoint).result()\n",
    "\n",
    "print('Deployment complete!')\n",
    "print(f'Scoring URI: {online_endpoint.scoring_uri}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140df5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the online endpoint\n",
    "test_samples = X_test.head(5).to_dict(orient='split')\n",
    "request_json = json.dumps({\n",
    "    'input_data': {\n",
    "        'columns': test_samples['columns'],\n",
    "        'data': test_samples['data'],\n",
    "    }\n",
    "})\n",
    "\n",
    "response = ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    deployment_name='blue',\n",
    "    request_file=None,\n",
    "    request_json=request_json,\n",
    ")\n",
    "\n",
    "print('Predictions:')\n",
    "print(json.loads(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330aff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Studio link\n",
    "studio_url = (\n",
    "    f'https://ml.azure.com/experiments/{experiment_name}'\n",
    "    f'?wsid=/subscriptions/{SUBSCRIPTION_ID}/resourceGroups/{RESOURCE_GROUP}'\n",
    "    f'/providers/Microsoft.MachineLearningServices/workspaces/{WORKSPACE_NAME}'\n",
    ")\n",
    "print('Open in Azure ML Studio:')\n",
    "print(studio_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e0330b",
   "metadata": {},
   "source": [
    "---\n",
    "## Cleanup\n",
    "\n",
    "Delete endpoints to avoid ongoing compute cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012c329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete endpoints\n",
    "\n",
    "# Delete batch endpoint\n",
    "# ml_client.batch_endpoints.begin_delete(name=batch_endpoint_name).result()\n",
    "# print('Deleted batch endpoint:', batch_endpoint_name)\n",
    "\n",
    "# Delete online endpoint (if created)\n",
    "# ml_client.online_endpoints.begin_delete(name=online_endpoint_name).result()\n",
    "# print('Deleted online endpoint:', online_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265338af",
   "metadata": {},
   "source": [
    "---\n",
    "## Key Takeaways\n",
    "\n",
    "1. **MLflow Integration**: Azure ML provides native MLflow tracking URI\n",
    "2. **NumPy Compatibility**: Pin `numpy<2.0` when logging models for Azure ML endpoints\n",
    "3. **Batch Scoring**: Use command jobs for ad-hoc batch inference\n",
    "4. **Batch Endpoints**: Use for production batch workloads with versioned deployments\n",
    "5. **Online Endpoints**: Use for real-time inference (higher cost)\n",
    "\n",
    "## Next Steps\n",
    "- Run `01-automated-retraining/submit_pipeline.py` for automated retraining\n",
    "- Run `02-observability/submit_drift_job.py` for drift detection\n",
    "- Run `03-governance/run_audit_report.py` for compliance auditing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e03798d7",
   "metadata": {},
   "source": [
    "# 01 ‚Äî Azure ML + MLflow Quickstart\n",
    "\n",
    "This notebook connects to an Azure ML workspace, sets MLflow tracking to the workspace, trains a simple model, logs metrics + artifacts, registers the model, and (optionally) deploys a managed online endpoint.\n",
    "\n",
    "## Prereqs\n",
    "- Azure subscription + access to the workshop resource group\n",
    "- Azure ML workspace deployed (see `infra/main.bicep`)\n",
    "- Auth: `DefaultAzureCredential` (recommended) or interactive browser fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88e5de3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK\n",
      "Python: c:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Scripts\\python.exe\n",
      "mlflow: 2.16.2 from c:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Lib\\site-packages\\mlflow\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "# If you're running this notebook in a fresh environment, run:\n",
    "# %pip install -r ../requirements.txt\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import sys\n",
    "import site\n",
    "\n",
    "# Avoid mixing user-site packages with the repo venv (prevents weird import conflicts).\n",
    "try:\n",
    "    user_site = site.getusersitepackages()\n",
    "    sys.path = [p for p in sys.path if os.path.normcase(p) != os.path.normcase(user_site)]\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Note: Do NOT delete mlflow/protobuf modules from sys.modules here.\n",
    "# Re-importing MLflow protos in the same kernel can trigger protobuf descriptor errors.\n",
    "# If you changed MLflow/protobuf versions, use 'Restart Kernel' in VS Code.\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.entities import Model, ManagedOnlineEndpoint, ManagedOnlineDeployment\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "print('Imports OK')\n",
    "print('Python:', sys.executable)\n",
    "print('mlflow:', mlflow.__version__, 'from', mlflow.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e736a462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded AZURE_SUBSCRIPTION_ID from Windows user environment (no kernel restart needed).\n",
      "Subscription: 1d53bfb3-a84c-4eb4-8c79-f29dc8424b6a\n",
      "Resource group: rg-dnd-mlops-demo\n",
      "Workspace: mlw-dndmlops2-dev\n"
     ]
    }
   ],
   "source": [
    "# Workshop configuration\n",
    "# Prefer environment variables so attendees don't have to edit the notebook.\n",
    "# If you prefer, you can also paste values directly into this cell.\n",
    "import subprocess\n",
    "import shutil\n",
    "import platform\n",
    "\n",
    "def _get_windows_persisted_env(var_name: str) -> str:\n",
    "    \"\"\"Read a persisted env var from Windows registry (HKCU/HKLM).\n",
    "    This helps when the kernel started before `setx` was run (no restart yet).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import winreg  # type: ignore\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "    for root, path in (\n",
    "        (winreg.HKEY_CURRENT_USER, r\"Environment\"),\n",
    "        (winreg.HKEY_LOCAL_MACHINE, r\"SYSTEM\\CurrentControlSet\\Control\\Session Manager\\Environment\"),\n",
    "    ):\n",
    "        try:\n",
    "            with winreg.OpenKey(root, path) as key:\n",
    "                value, _ = winreg.QueryValueEx(key, var_name)\n",
    "                if isinstance(value, str) and value.strip():\n",
    "                    return value.strip()\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        except OSError:\n",
    "            continue\n",
    "    return \"\"\n",
    "\n",
    "SUBSCRIPTION_ID = os.getenv('AZURE_SUBSCRIPTION_ID', '').strip()\n",
    "RESOURCE_GROUP = os.getenv('AZURE_RESOURCE_GROUP', 'rg-dnd-mlops-demo').strip()\n",
    "WORKSPACE_NAME = os.getenv('AZURE_ML_WORKSPACE', 'mlw-dndmlops2-dev').strip()\n",
    "\n",
    "# If the kernel started before `setx`, os.getenv won't see the new value.\n",
    "# On Windows, try loading the persisted user env var from the registry.\n",
    "if not SUBSCRIPTION_ID and platform.system() == 'Windows':\n",
    "    persisted = _get_windows_persisted_env('AZURE_SUBSCRIPTION_ID')\n",
    "    if persisted:\n",
    "        SUBSCRIPTION_ID = persisted\n",
    "        os.environ['AZURE_SUBSCRIPTION_ID'] = SUBSCRIPTION_ID\n",
    "        print('Loaded AZURE_SUBSCRIPTION_ID from Windows user environment (no kernel restart needed).')\n",
    "\n",
    "# Optional manual override (uncomment and paste):\n",
    "# SUBSCRIPTION_ID = \"<your-subscription-id>\"\n",
    "\n",
    "if not SUBSCRIPTION_ID and shutil.which('az'):\n",
    "    try:\n",
    "        SUBSCRIPTION_ID = subprocess.check_output(\n",
    "            ['az', 'account', 'show', '--query', 'id', '-o', 'tsv'],\n",
    "            text=True,\n",
    "            stderr=subprocess.STDOUT,\n",
    "        ).strip()\n",
    "        if SUBSCRIPTION_ID:\n",
    "            os.environ['AZURE_SUBSCRIPTION_ID'] = SUBSCRIPTION_ID\n",
    "            print('Using subscription from Azure CLI context (az account show).')\n",
    "    except Exception as e:\n",
    "        print('Azure CLI fallback failed:', repr(e))\n",
    "\n",
    "if not SUBSCRIPTION_ID:\n",
    "    raise ValueError(\n",
    "        'Missing AZURE_SUBSCRIPTION_ID. Set it as an env var (or restart kernel after setx), '\n",
    "        'or uncomment the manual override in this cell.'\n",
    "    )\n",
    "\n",
    "print('Subscription:', SUBSCRIPTION_ID)\n",
    "print('Resource group:', RESOURCE_GROUP)\n",
    "print('Workspace:', WORKSPACE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2c4a8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class DeploymentTemplateOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to workspace: mlw-dndmlops2-dev\n"
     ]
    }
   ],
   "source": [
    "# Authenticate and connect to Azure ML\n",
    "try:\n",
    "    credential = DefaultAzureCredential(exclude_interactive_browser_credential=True)\n",
    "    credential.get_token('https://management.azure.com/.default')\n",
    "except Exception:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=SUBSCRIPTION_ID,\n",
    "    resource_group_name=RESOURCE_GROUP,\n",
    "    workspace_name=WORKSPACE_NAME,\n",
    ")\n",
    "\n",
    "print('Connected to workspace:', ml_client.workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16b2c54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI: azureml://eastus.api.azureml.ms/mlflow/v2.0/subscriptions/1d53bfb3-a84c-4eb4-8c79-f29dc8424b6a/resourceGroups/rg-dnd-mlops-demo/providers/Microsoft.MachineLearningServices/workspaces/mlw-dndmlops2-dev\n",
      "Experiment: mlops-hackathon-demo\n"
     ]
    }
   ],
   "source": [
    "# Configure MLflow to use Azure ML workspace tracking\n",
    "tracking_uri = ml_client.workspaces.get(WORKSPACE_NAME).mlflow_tracking_uri\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "experiment_name = os.getenv('MLFLOW_EXPERIMENT_NAME', 'mlops-hackathon-demo')\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print('MLflow tracking URI:', tracking_uri)\n",
    "print('Experiment:', experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71da7ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'true'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional: avoid Azure CLI credential timeouts when logging artifacts\n",
    "import os\n",
    "os.environ.setdefault(\"AZURE_IDENTITY_DISABLE_AZURECLI\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b0924c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Spambase dataset from OpenML...\n",
      "Train: (3680, 57) Test: (921, 57)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_%3B</th>\n",
       "      <th>char_freq_%28</th>\n",
       "      <th>char_freq_%5B</th>\n",
       "      <th>char_freq_%21</th>\n",
       "      <th>char_freq_%24</th>\n",
       "      <th>char_freq_%23</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2940</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.880</td>\n",
       "      <td>45</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.52</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.013</td>\n",
       "      <td>6.395</td>\n",
       "      <td>583</td>\n",
       "      <td>1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.933</td>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.333</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.153</td>\n",
       "      <td>53</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "2940            0.05               0.00           0.45           0.0   \n",
       "1303            0.17               0.26           1.21           0.0   \n",
       "3468            0.00               0.00           0.00           0.0   \n",
       "3181            0.00               0.00           0.00           0.0   \n",
       "794             0.00               0.56           0.00           0.0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "2940           0.15             0.1              0.00                0.00   \n",
       "1303           0.43             0.6              0.43                0.26   \n",
       "3468           0.00             0.0              0.00                0.00   \n",
       "3181           0.00             0.0              0.00                0.00   \n",
       "794            0.56             0.0              0.00                0.00   \n",
       "\n",
       "      word_freq_order  word_freq_mail  ...  word_freq_conference  \\\n",
       "2940             0.55            0.00  ...                   0.0   \n",
       "1303             0.69            0.52  ...                   0.0   \n",
       "3468             0.00            0.00  ...                   0.0   \n",
       "3181             0.00            0.00  ...                   0.0   \n",
       "794              1.01            0.56  ...                   0.0   \n",
       "\n",
       "      char_freq_%3B  char_freq_%28  char_freq_%5B  char_freq_%21  \\\n",
       "2940          0.203          0.195           0.05          0.000   \n",
       "1303          0.000          0.108           0.00          0.271   \n",
       "3468          0.000          0.000           0.00          0.153   \n",
       "3181          0.000          0.000           0.00          0.000   \n",
       "794           0.000          0.186           0.00          0.056   \n",
       "\n",
       "      char_freq_%24  char_freq_%23  capital_run_length_average  \\\n",
       "2940          0.014          0.000                       2.880   \n",
       "1303          0.243          0.013                       6.395   \n",
       "3468          0.000          0.000                       1.933   \n",
       "3181          0.000          0.000                       4.333   \n",
       "794           0.056          0.000                       2.153   \n",
       "\n",
       "      capital_run_length_longest  capital_run_length_total  \n",
       "2940                          45                      1080  \n",
       "1303                         583                      1375  \n",
       "3468                           7                        58  \n",
       "3181                          20                        26  \n",
       "794                           53                       532  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset (OpenML Spambase)\n",
    "print('Loading Spambase dataset from OpenML...')\n",
    "spambase = fetch_openml(data_id=44, as_frame=True, parser='auto')\n",
    "data = spambase.frame.rename(columns={'class': 'is_spam'})\n",
    "data['is_spam'] = data['is_spam'].astype(int)\n",
    "\n",
    "X = data.drop('is_spam', axis=1)\n",
    "y = data['is_spam']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print('Train:', X_train.shape, 'Test:', X_test.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69ef5d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'spam-classifier' already exists. Creating a new version of this model...\n",
      "2026/02/04 14:42:15 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: spam-classifier, version 5\n",
      "Created version '5' of model 'spam-classifier'.\n",
      "2026/02/04 14:42:22 INFO mlflow.tracking._tracking_service.client: üèÉ View run spam-classifier-rf at: https://eastus.api.azureml.ms/mlflow/v2.0/subscriptions/1d53bfb3-a84c-4eb4-8c79-f29dc8424b6a/resourceGroups/rg-dnd-mlops-demo/providers/Microsoft.MachineLearningServices/workspaces/mlw-dndmlops2-dev/#/experiments/5a65b315-6ff3-4683-9f81-002232b041c1/runs/6cab43f8-6e4b-4d2b-9aaa-a3be6c084287.\n",
      "2026/02/04 14:42:22 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://eastus.api.azureml.ms/mlflow/v2.0/subscriptions/1d53bfb3-a84c-4eb4-8c79-f29dc8424b6a/resourceGroups/rg-dnd-mlops-demo/providers/Microsoft.MachineLearningServices/workspaces/mlw-dndmlops2-dev/#/experiments/5a65b315-6ff3-4683-9f81-002232b041c1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 6cab43f8-6e4b-4d2b-9aaa-a3be6c084287\n",
      "Metrics: {'accuracy': 0.9348534201954397, 'precision': 0.9495548961424333, 'recall': 0.8815426997245179, 'f1_score': 0.9142857142857143, 'roc_auc': 0.9802867383512545}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>char_freq_%21</td>\n",
       "      <td>0.130966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>char_freq_%24</td>\n",
       "      <td>0.117364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>word_freq_remove</td>\n",
       "      <td>0.095036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>word_freq_free</td>\n",
       "      <td>0.074471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>capital_run_length_average</td>\n",
       "      <td>0.056725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>capital_run_length_total</td>\n",
       "      <td>0.054680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>capital_run_length_longest</td>\n",
       "      <td>0.049536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>word_freq_hp</td>\n",
       "      <td>0.046051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>word_freq_your</td>\n",
       "      <td>0.044948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>word_freq_money</td>\n",
       "      <td>0.034451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature  importance\n",
       "51               char_freq_%21    0.130966\n",
       "52               char_freq_%24    0.117364\n",
       "6             word_freq_remove    0.095036\n",
       "15              word_freq_free    0.074471\n",
       "54  capital_run_length_average    0.056725\n",
       "56    capital_run_length_total    0.054680\n",
       "55  capital_run_length_longest    0.049536\n",
       "24                word_freq_hp    0.046051\n",
       "20              word_freq_your    0.044948\n",
       "23             word_freq_money    0.034451"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train + log to MLflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'random_state': 42,\n",
    "}\n",
    "\n",
    "with mlflow.start_run(run_name='spam-classifier-rf') as run:\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param('training_samples', len(X_train))\n",
    "    mlflow.log_param('dataset', 'UCI Spambase')\n",
    "    mlflow.log_param('num_features', X_train.shape[1])\n",
    "\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_pred_proba),\n",
    "    }\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    feature_importance = (\n",
    "        pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_})\n",
    "        .sort_values('importance', ascending=False)\n",
    "    )\n",
    "    feature_importance.to_csv('feature_importance.csv', index=False)\n",
    "    mlflow.log_artifact('feature_importance.csv')\n",
    "\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        model,\n",
    "        artifact_path='model',\n",
    "        signature=signature,\n",
    "        registered_model_name='spam-classifier',\n",
    "    )\n",
    "\n",
    "print('Run ID:', run.info.run_id)\n",
    "print('Metrics:', metrics)\n",
    "feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "601b20a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered: spam-classifier 6\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Register model in Azure ML with governance metadata\n",
    "# Note: MLflow registration above already creates a registered model in many setups.\n",
    "# This step adds explicit tags/properties via the Azure ML SDK.\n",
    "\n",
    "model_uri = f'runs:/{run.info.run_id}/model'\n",
    "\n",
    "registered_model = ml_client.models.create_or_update(\n",
    "    Model(\n",
    "        path=model_uri,\n",
    "        name='spam-classifier',\n",
    "        type=AssetTypes.MLFLOW_MODEL,\n",
    "        description='Email spam classifier trained on UCI Spambase dataset',\n",
    "        tags={\n",
    "            'author': os.getenv('MODEL_AUTHOR', 'workshop-attendee'),\n",
    "            'use_case': 'spam_detection',\n",
    "            'dataset': 'UCI Spambase',\n",
    "            'framework': 'sklearn',\n",
    "            'algorithm': 'RandomForest',\n",
    "        },\n",
    "        properties={k: str(round(v, 4)) for k, v in metrics.items()},\n",
    "    )\n",
    ")\n",
    "\n",
    "print('Model registered:', registered_model.name, registered_model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1addcb",
   "metadata": {},
   "source": [
    "## Fix: Re-log Model with NumPy 1.x Constraint\n",
    "\n",
    "MLflow embeds conda/pip dependencies when logging a model. If the model was logged with NumPy 2.x, Azure ML's curated environments (which use NumPy 1.x) will fail to load it.\n",
    "\n",
    "**Solution**: Re-log the model with explicit `pip_requirements` specifying `numpy<2.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a5f2044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Lib\\site-packages\\mlflow\\types\\utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'spam-classifier' already exists. Creating a new version of this model...\n",
      "2026/02/04 21:49:45 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: spam-classifier, version 7\n",
      "Created version '7' of model 'spam-classifier'.\n",
      "2026/02/04 21:49:48 INFO mlflow.tracking._tracking_service.client: üèÉ View run spam-classifier-rf-numpy1x at: https://eastus.api.azureml.ms/mlflow/v2.0/subscriptions/1d53bfb3-a84c-4eb4-8c79-f29dc8424b6a/resourceGroups/rg-dnd-mlops-demo/providers/Microsoft.MachineLearningServices/workspaces/mlw-dndmlops2-dev/#/experiments/5a65b315-6ff3-4683-9f81-002232b041c1/runs/fa046904-ce27-4847-a34a-03e82f662cd4.\n",
      "2026/02/04 21:49:48 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://eastus.api.azureml.ms/mlflow/v2.0/subscriptions/1d53bfb3-a84c-4eb4-8c79-f29dc8424b6a/resourceGroups/rg-dnd-mlops-demo/providers/Microsoft.MachineLearningServices/workspaces/mlw-dndmlops2-dev/#/experiments/5a65b315-6ff3-4683-9f81-002232b041c1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: fa046904-ce27-4847-a34a-03e82f662cd4\n",
      "Model logged with pip_requirements: ['numpy<2.0', 'scikit-learn>=1.0,<2.0', 'pandas', 'mlflow']\n"
     ]
    }
   ],
   "source": [
    "# Re-log the model with explicit numpy<2.0 constraint\n",
    "# This ensures the model's embedded environment is compatible with Azure ML\n",
    "\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# Define explicit pip requirements that work with Azure ML\n",
    "pip_requirements = [\n",
    "    \"numpy<2.0\",\n",
    "    \"scikit-learn>=1.0,<2.0\",\n",
    "    \"pandas\",\n",
    "    \"mlflow\",\n",
    "]\n",
    "\n",
    "with mlflow.start_run(run_name='spam-classifier-rf-numpy1x') as run:\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param('training_samples', len(X_train))\n",
    "    mlflow.log_param('dataset', 'UCI Spambase')\n",
    "    mlflow.log_param('numpy_constraint', '<2.0')\n",
    "    \n",
    "    # Use the already-trained model from memory\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "    \n",
    "    # Log with explicit pip_requirements to override auto-detected deps\n",
    "    mlflow.sklearn.log_model(\n",
    "        model,\n",
    "        artifact_path='model',\n",
    "        signature=signature,\n",
    "        pip_requirements=pip_requirements,\n",
    "        registered_model_name='spam-classifier',\n",
    "    )\n",
    "\n",
    "print(f'Run ID: {run.info.run_id}')\n",
    "print(f'Model logged with pip_requirements: {pip_requirements}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "473d24dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered: spam-classifier:8\n",
      "This model version has numpy<2.0 embedded - endpoints should work now!\n"
     ]
    }
   ],
   "source": [
    "# Register the fixed model in Azure ML\n",
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "model_uri = f'runs:/{run.info.run_id}/model'\n",
    "\n",
    "registered_model = ml_client.models.create_or_update(\n",
    "    Model(\n",
    "        path=model_uri,\n",
    "        name='spam-classifier',\n",
    "        type=AssetTypes.MLFLOW_MODEL,\n",
    "        description='Email spam classifier (numpy<2.0 compatible)',\n",
    "        tags={\n",
    "            'author': os.getenv('MODEL_AUTHOR', 'workshop-attendee'),\n",
    "            'use_case': 'spam_detection',\n",
    "            'dataset': 'UCI Spambase',\n",
    "            'framework': 'sklearn',\n",
    "            'numpy_constraint': '<2.0',\n",
    "        },\n",
    "        properties={k: str(round(v, 4)) for k, v in metrics.items()},\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f'Model registered: {registered_model.name}:{registered_model.version}')\n",
    "print('This model version has numpy<2.0 embedded - endpoints should work now!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1075bf8",
   "metadata": {},
   "source": [
    "## Batch scoring demo (recommended)\n",
    "This section runs **asynchronous batch scoring** as an Azure ML job (offline inference).\n",
    "- No online endpoint required\n",
    "- Produces a CSV output you can download and inspect\n",
    "- Uses the registered MLflow model in the Azure ML model registry\n",
    "\n",
    "After this, the notebook includes an **optional** real-time serving section (managed online endpoint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a2f1274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model from model registration: spam-classifier 6\n",
      "Model reference: azureml:spam-classifier:6\n",
      "Batch rows: 100\n"
     ]
    }
   ],
   "source": [
    "# Batch scoring (1/3): resolve the model reference (no local uploads)\n",
    "from typing import Optional\n",
    "\n",
    "from azure.ai.ml import Input, Output, command\n",
    "\n",
    "# Resolve a model to use for scoring.\n",
    "# Prefer the explicit Azure ML registration cell output if you ran it; otherwise, pick the latest version by name.\n",
    "model_name = os.getenv('BATCH_MODEL_NAME', 'spam-classifier').strip()\n",
    "model_version: Optional[str] = os.getenv('BATCH_MODEL_VERSION', '').strip() or None\n",
    "\n",
    "if 'registered_model' in globals() and getattr(registered_model, 'name', None):\n",
    "    model_name = registered_model.name\n",
    "    model_version = str(registered_model.version)\n",
    "    print('Using model from model registration:', model_name, model_version)\n",
    "else:\n",
    "    if model_version is None:\n",
    "        versions = list(ml_client.models.list(name=model_name))\n",
    "        if not versions:\n",
    "            raise RuntimeError(\n",
    "                f'No Azure ML model named {model_name!r} found. '\n",
    "                'Run the model registration cell, or set BATCH_MODEL_NAME / BATCH_MODEL_VERSION.'\n",
    "            )\n",
    "        def _version_key(m):\n",
    "            try:\n",
    "                return int(str(m.version))\n",
    "            except Exception:\n",
    "                return -1\n",
    "        latest = sorted(versions, key=_version_key, reverse=True)[0]\n",
    "        model_version = str(latest.version)\n",
    "        print('Resolved latest model version:', model_name, model_version)\n",
    "\n",
    "model_ref = f'azureml:{model_name}:{model_version}'\n",
    "print('Model reference:', model_ref)\n",
    "\n",
    "# How many rows to score (downloaded inside the job).\n",
    "batch_n_rows = int(os.getenv('BATCH_N_ROWS', '100'))\n",
    "print('Batch rows:', batch_n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d539485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBAC preflight: identify which identities need Storage Blob Data roles\n",
    "import json\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "ws = ml_client.workspaces.get(WORKSPACE_NAME)\n",
    "ds = ml_client.datastores.get('workspaceartifactstore')\n",
    "compute_name = batch_compute if 'batch_compute' in globals() else os.getenv('AML_BATCH_COMPUTE', '').strip()\n",
    "\n",
    "print('Workspace:', ws.name)\n",
    "print('Workspace identity type:', getattr(getattr(ws, 'identity', None), 'type', None))\n",
    "print('Workspace principal_id:', getattr(getattr(ws, 'identity', None), 'principal_id', None))\n",
    "print('Workspace tenant_id:', getattr(getattr(ws, 'identity', None), 'tenant_id', None))\n",
    "\n",
    "print('workspaceartifactstore account:', getattr(ds, 'account_name', None))\n",
    "print('workspaceartifactstore container:', getattr(ds, 'container_name', None))\n",
    "\n",
    "if compute_name:\n",
    "    try:\n",
    "        c = ml_client.compute.get(compute_name)\n",
    "        ident = getattr(c, 'identity', None)\n",
    "        print('Compute:', c.name, 'type:', c.type)\n",
    "        print('Compute identity type:', getattr(ident, 'type', None))\n",
    "        print('Compute principal_id:', getattr(ident, 'principal_id', None))\n",
    "        print('Compute tenant_id:', getattr(ident, 'tenant_id', None))\n",
    "    except Exception as e:\n",
    "        print('Could not load compute identity:', repr(e))\n",
    "else:\n",
    "    print('Compute not set yet; run Batch scoring (2/3) once to auto-select compute, then re-run this cell.')\n",
    "\n",
    "# Best-effort: resolve storage account ARM id (scope) so you can paste it into RBAC commands.\n",
    "storage_account_id = getattr(ws, 'storage_account', None)\n",
    "if storage_account_id:\n",
    "    print('Workspace storage_account resource id:', storage_account_id)\n",
    "elif shutil.which('az') and getattr(ds, 'account_name', None):\n",
    "    try:\n",
    "        storage_account_id = subprocess.check_output(\n",
    "            ['az', 'storage', 'account', 'show', '-n', ds.account_name, '--query', 'id', '-o', 'tsv'],\n",
    "            text=True,\n",
    "            stderr=subprocess.STDOUT,\n",
    "        ).strip()\n",
    "        print('Resolved storage account resource id (via az):', storage_account_id)\n",
    "    except Exception as e:\n",
    "        print('Could not resolve storage account id via az:', repr(e))\n",
    "else:\n",
    "    print('Could not resolve storage account ARM id automatically (no ws.storage_account and/or az not available).')\n",
    "\n",
    "print('\\nRBAC target roles (apply on the storage account):')\n",
    "print(' - Storage Blob Data Reader (minimum)')\n",
    "print(' - Storage Blob Data Contributor (often required)')\n",
    "print('Grant to the principal_id for: workspace identity, compute identity, and (later) online endpoint identity.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c43e2bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available compute targets (name -> type):\n",
      " - cpu-cluster -> amlcompute\n",
      "Auto-selected compute: cpu-cluster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch scoring job: mango_tongue_rn0rx6my87\n",
      "Compute: cpu-cluster\n",
      "Watch logs with: ml_client.jobs.stream(submitted.name)\n"
     ]
    }
   ],
   "source": [
    "# Batch scoring (2/3): submit an offline scoring job (no local uploads)\n",
    "# Why this looks a bit different: some secured workspaces disable key-based auth on the default storage account.\n",
    "# In that case, Azure ML can't upload local files (code/input) using account-key SAS tokens.\n",
    "# So this job downloads data inside the container and only uses the registered model asset as an input.\n",
    "\n",
    "from azure.ai.ml.entities import UserIdentityConfiguration\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "# Compute for the batch job.\n",
    "batch_compute = os.getenv('AML_BATCH_COMPUTE', '').strip()\n",
    "\n",
    "if not batch_compute:\n",
    "    computes = list(ml_client.compute.list())\n",
    "    print('Available compute targets (name -> type):')\n",
    "    for c in computes:\n",
    "        name = getattr(c, 'name', None)\n",
    "        ctype = getattr(c, 'type', None)\n",
    "        if name:\n",
    "            print(' -', name, '->', ctype)\n",
    "    aml_compute_names = [\n",
    "        getattr(c, 'name', None) for c in computes\n",
    "        if getattr(c, 'name', None)\n",
    "        and ('amlcompute' in str(getattr(c, 'type', '')).lower() or 'amlcompute' in c.__class__.__name__.lower())\n",
    "    ]\n",
    "    if not aml_compute_names:\n",
    "        raise RuntimeError('No AmlCompute cluster found. Create one in Azure ML Studio.')\n",
    "    batch_compute = aml_compute_names[0]\n",
    "    print('Auto-selected compute:', batch_compute)\n",
    "else:\n",
    "    print('Using compute from AML_BATCH_COMPUTE:', batch_compute)\n",
    "\n",
    "# Use a recent curated environment with sklearn 1.5+ from public registry (no ACR pull needed).\n",
    "# The sklearn-1.5 environment has Python 3.10 and scikit-learn >= 1.5 which matches the model.\n",
    "batch_env = 'azureml://registries/azureml/environments/sklearn-1.5/labels/latest'\n",
    "\n",
    "# Heredoc script avoids quoting issues.\n",
    "inline_command = \"\"\"python - <<'PYSCRIPT'\n",
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "model_dir = r\"${{inputs.model}}\"\n",
    "out_dir = r\"${{outputs.predictions}}\"\n",
    "n_rows = __N_ROWS__\n",
    "\n",
    "spambase = fetch_openml(data_id=44, as_frame=True, parser='auto')\n",
    "data = spambase.frame.rename(columns={'class': 'is_spam'})\n",
    "X = data.drop('is_spam', axis=1).head(n_rows)\n",
    "\n",
    "model = mlflow.pyfunc.load_model(model_dir)\n",
    "preds = model.predict(X)\n",
    "\n",
    "out = pd.DataFrame({'prediction': preds})\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_path = os.path.join(out_dir, 'predictions.csv')\n",
    "out.to_csv(out_path, index=False)\n",
    "print('Wrote:', out_path)\n",
    "PYSCRIPT\n",
    "\"\"\"\n",
    "inline_command = inline_command.replace('__N_ROWS__', str(batch_n_rows))\n",
    "\n",
    "batch_job = command(\n",
    "    command=inline_command,\n",
    "    inputs={\n",
    "        'model': Input(type='mlflow_model', path=model_ref, mode='download'),\n",
    "    },\n",
    "    outputs={\n",
    "        'predictions': Output(type='uri_folder'),\n",
    "    },\n",
    "    environment=batch_env,\n",
    "    compute=batch_compute,\n",
    "    experiment_name=experiment_name,\n",
    "    display_name='batch-score-spam-classifier',\n",
    "    identity=UserIdentityConfiguration(),\n",
    ")\n",
    "\n",
    "submitted = ml_client.jobs.create_or_update(batch_job)\n",
    "print('Submitted batch scoring job:', submitted.name)\n",
    "print('Compute:', batch_compute)\n",
    "print('Watch logs with: ml_client.jobs.stream(submitted.name)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "290fcd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: Queued\n",
      "Job status: Queued\n",
      "Job status: Queued\n",
      "Job status: Queued\n",
      "Job status: Queued\n",
      "Job status: Queued\n",
      "Job status: Queued\n",
      "Job status: Queued\n",
      "Job status: Queued\n",
      "Job status: Queued\n",
      "Job status: Queued\n",
      "Job status: Queued\n",
      "Job status: Running\n",
      "Job status: Running\n",
      "Job status: Running\n",
      "Job status: Running\n",
      "Job status: Running\n",
      "Job status: Running\n",
      "Job status: Running\n",
      "Job status: Running\n",
      "Job status: Running\n",
      "Job status: Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifact azureml://subscriptions/1d53bfb3-a84c-4eb4-8c79-f29dc8424b6a/resourcegroups/rg-dnd-mlops-demo/workspaces/mlw-dndmlops2-dev/datastores/workspaceblobstore/paths/azureml/mango_tongue_rn0rx6my87/predictions/ to batch_outputs\\mango_tongue_rn0rx6my87\\named-outputs\\predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded job output to: C:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\notebooks\\batch_outputs\\mango_tongue_rn0rx6my87\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction\n",
       "0           1\n",
       "1           1\n",
       "2           1\n",
       "3           1\n",
       "4           1\n",
       "5           0\n",
       "6           1\n",
       "7           0\n",
       "8           1\n",
       "9           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Batch scoring (3/3): download output + inspect predictions (and show logs on failure)\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "if 'submitted' not in globals():\n",
    "    raise RuntimeError('Run the Batch scoring (2/3) cell first to submit the job.')\n",
    "\n",
    "# Wait for job completion (up to 15 minutes by default) so this cell is \"one-click\" in workshops.\n",
    "wait_seconds = int(os.getenv('BATCH_WAIT_SECONDS', '900'))\n",
    "poll_seconds = int(os.getenv('BATCH_POLL_SECONDS', '15'))\n",
    "\n",
    "start = time.time()\n",
    "status = None\n",
    "while True:\n",
    "    status = ml_client.jobs.get(submitted.name).status\n",
    "    print('Job status:', status)\n",
    "    if status in {'Completed', 'Failed', 'Canceled'}:\n",
    "        break\n",
    "    if time.time() - start > wait_seconds:\n",
    "        print('Job still running; re-run this cell in a bit to download outputs.')\n",
    "        break\n",
    "    time.sleep(poll_seconds)\n",
    "\n",
    "if status == 'Completed':\n",
    "    download_dir = Path('batch_outputs') / submitted.name\n",
    "    download_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    ml_client.jobs.download(\n",
    "        name=submitted.name,\n",
    "        download_path=str(download_dir),\n",
    "        output_name='predictions',\n",
    "    )\n",
    "    print('Downloaded job output to:', str(download_dir.resolve()))\n",
    "\n",
    "    pred_path = download_dir / 'named-outputs' / 'predictions' / 'predictions.csv'\n",
    "    if pred_path.exists():\n",
    "        preds = pd.read_csv(pred_path)\n",
    "        display(preds.head(10))\n",
    "    else:\n",
    "        print('Predictions file not found in downloaded output. Check job outputs in Studio for details.')\n",
    "else:\n",
    "    # If the job failed, surface logs and still complete the demo via a local fallback.\n",
    "    if status in {'Failed', 'Canceled'}:\n",
    "        print('Job did not complete successfully. Streaming logs (if available)...')\n",
    "        try:\n",
    "            ml_client.jobs.stream(submitted.name)\n",
    "        except Exception as e:\n",
    "            print('Could not stream logs from this client/session:', repr(e))\n",
    "            print('Open the job in Azure ML Studio for full details:', getattr(submitted, 'studio_url', None) or '(see the Web View link above if printed)')\n",
    "\n",
    "        print('')\n",
    "        print('Fallback: running batch scoring locally in this notebook (offline inference)')\n",
    "        # Use the in-kernel trained model if present; otherwise try to load from MLflow run artifact.\n",
    "        if 'model' in globals():\n",
    "            scorer = model\n",
    "            predict_fn = scorer.predict\n",
    "        else:\n",
    "            loaded = mlflow.pyfunc.load_model(model_uri)\n",
    "            predict_fn = loaded.predict\n",
    "\n",
    "        X_batch = (X_test if 'X_test' in globals() else X).head(int(batch_n_rows) if 'batch_n_rows' in globals() else 100)\n",
    "        local_preds = predict_fn(X_batch)\n",
    "        local_out = pd.DataFrame({'prediction': local_preds})\n",
    "        local_dir = Path('batch_outputs') / 'local_fallback'\n",
    "        local_dir.mkdir(parents=True, exist_ok=True)\n",
    "        local_path = local_dir / 'predictions.csv'\n",
    "        local_out.to_csv(local_path, index=False)\n",
    "        print('Wrote local predictions to:', str(local_path.resolve()))\n",
    "        display(local_out.head(10))\n",
    "    else:\n",
    "        print('Job not completed yet. Re-run this cell later to download outputs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c464ff5",
   "metadata": {},
   "source": [
    "## Batch Endpoint (Recommended for Production)\n",
    "\n",
    "A **Batch Endpoint** provides a durable REST endpoint for batch inference:\n",
    "- No always-on compute (cost-efficient)\n",
    "- Process large datasets asynchronously\n",
    "- Versioned deployments with traffic routing\n",
    "- Built-in job management and monitoring\n",
    "\n",
    "This is different from the \"batch scoring job\" above - a batch endpoint is a **permanent, reusable endpoint** that can be invoked via REST API or SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a2a45f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating batch endpoint: spam-batch-241391f6\n",
      "Batch endpoint created: spam-batch-241391f6\n"
     ]
    }
   ],
   "source": [
    "# Batch Endpoint (1/3): Create the batch endpoint\n",
    "from azure.ai.ml.entities import BatchEndpoint, BatchDeployment, BatchRetrySettings\n",
    "from azure.ai.ml.constants import BatchDeploymentOutputAction\n",
    "import uuid\n",
    "\n",
    "# Create a unique batch endpoint name\n",
    "batch_endpoint_name = os.getenv('AML_BATCH_ENDPOINT_NAME', f'spam-batch-{uuid.uuid4().hex[:8]}')\n",
    "\n",
    "batch_endpoint = BatchEndpoint(\n",
    "    name=batch_endpoint_name,\n",
    "    description='Spam classifier batch endpoint for async inference',\n",
    "    tags={'environment': 'workshop', 'use_case': 'spam_detection'},\n",
    ")\n",
    "\n",
    "print(f'Creating batch endpoint: {batch_endpoint_name}')\n",
    "ml_client.batch_endpoints.begin_create_or_update(batch_endpoint).result()\n",
    "print(f'Batch endpoint created: {batch_endpoint_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "224cd326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: azureml:spam-classifier:8\n",
      "Creating batch deployment: numpy1x\n",
      "Batch deployment \"numpy1x\" created and set as default\n",
      "Model: azureml:spam-classifier:8\n",
      "Endpoint: spam-batch-241391f6\n"
     ]
    }
   ],
   "source": [
    "# Batch Endpoint (2/3): Create/update deployment with the fixed model (numpy<2.0)\n",
    "from azure.ai.ml.entities import ModelBatchDeployment, ModelBatchDeploymentSettings, Environment\n",
    "from azure.ai.ml.constants import BatchDeploymentOutputAction\n",
    "\n",
    "# Use the registered model (version 8 has numpy<2.0)\n",
    "model_for_batch = f'azureml:{registered_model.name}:{registered_model.version}'\n",
    "print(f'Using model: {model_for_batch}')\n",
    "\n",
    "# Use the sklearn-1.5 curated environment (also has numpy<2.0)\n",
    "batch_endpoint_env = 'azureml://registries/azureml/environments/sklearn-1.5/labels/latest'\n",
    "\n",
    "# Create a new deployment name (must be 3+ chars)\n",
    "deployment_name = 'numpy1x'\n",
    "\n",
    "batch_deployment = ModelBatchDeployment(\n",
    "    name=deployment_name,\n",
    "    endpoint_name=batch_endpoint_name,\n",
    "    model=model_for_batch,\n",
    "    environment=batch_endpoint_env,\n",
    "    compute=batch_compute,\n",
    "    settings=ModelBatchDeploymentSettings(\n",
    "        instance_count=1,\n",
    "        max_concurrency_per_instance=2,\n",
    "        mini_batch_size=10,\n",
    "        output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
    "        output_file_name='predictions.csv',\n",
    "        retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n",
    "        logging_level='info',\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(f'Creating batch deployment: {deployment_name}')\n",
    "ml_client.batch_deployments.begin_create_or_update(batch_deployment).result()\n",
    "\n",
    "# Set as default deployment\n",
    "batch_endpoint = ml_client.batch_endpoints.get(batch_endpoint_name)\n",
    "batch_endpoint.defaults.deployment_name = deployment_name\n",
    "ml_client.batch_endpoints.begin_create_or_update(batch_endpoint).result()\n",
    "\n",
    "print(f'Batch deployment \"{deployment_name}\" created and set as default')\n",
    "print(f'Model: {model_for_batch}')\n",
    "print(f'Endpoint: {batch_endpoint_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82fa71cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created input file: batch_endpoint_input.csv (50 rows)\n",
      "Batch job submitted: batchjob-14b1e65b-c9e3-4807-9297-fc1ae3035ff9\n",
      "Monitor in Studio: https://ml.azure.com/runs/batchjob-14b1e65b-c9e3-4807-9297-fc1ae3035ff9?wsid=/subscriptions/1d53bfb3-a84c-4eb4-8c79-f29dc8424b6a/resourcegroups/rg-dnd-mlops-demo/workspaces/mlw-dndmlops2-dev\n"
     ]
    }
   ],
   "source": [
    "# Batch Endpoint (3/3): Invoke the batch endpoint with test data\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# Create a small CSV file with test data to score\n",
    "batch_input_path = Path('batch_endpoint_input.csv')\n",
    "X_test.head(50).to_csv(batch_input_path, index=False)\n",
    "print(f'Created input file: {batch_input_path} ({len(X_test.head(50))} rows)')\n",
    "\n",
    "# Invoke the batch endpoint\n",
    "# Note: For production, you'd typically use a registered data asset or datastore path\n",
    "job = ml_client.batch_endpoints.invoke(\n",
    "    endpoint_name=batch_endpoint_name,\n",
    "    inputs={\n",
    "        'input': Input(path=str(batch_input_path.resolve()), type=AssetTypes.URI_FILE)\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f'Batch job submitted: {job.name}')\n",
    "print(f'Monitor in Studio: https://ml.azure.com/runs/{job.name}?wsid=/subscriptions/{SUBSCRIPTION_ID}/resourcegroups/{RESOURCE_GROUP}/workspaces/{WORKSPACE_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ead06213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AzureCliCredential.get_token failed: Failed to invoke the Azure CLI\n",
      "Proceeding with no tenant id appended to studio URL\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch job status: Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifact azureml://datastores/workspaceblobstore/paths/azureml/23d8758a-1dc1-4213-abe9-956d87565cfb/score/ to batch_endpoint_outputs\\batchjob-14b1e65b-c9e3-4807-9297-fc1ae3035ff9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded results to: batch_endpoint_outputs\\batchjob-14b1e65b-c9e3-4807-9297-fc1ae3035ff9\n",
      "\\nPredictions from batch_endpoint_outputs\\batchjob-14b1e65b-c9e3-4807-9297-fc1ae3035ff9\\predictions.csv:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>batch_endpoint_input.csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>batch_endpoint_input.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>batch_endpoint_input.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>batch_endpoint_input.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>batch_endpoint_input.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>batch_endpoint_input.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>batch_endpoint_input.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>batch_endpoint_input.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>batch_endpoint_input.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>batch_endpoint_input.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>batch_endpoint_input.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1  batch_endpoint_input.csv\n",
       "0   1  1  batch_endpoint_input.csv\n",
       "1   2  0  batch_endpoint_input.csv\n",
       "2   3  1  batch_endpoint_input.csv\n",
       "3   4  0  batch_endpoint_input.csv\n",
       "4   5  0  batch_endpoint_input.csv\n",
       "5   6  0  batch_endpoint_input.csv\n",
       "6   7  1  batch_endpoint_input.csv\n",
       "7   8  0  batch_endpoint_input.csv\n",
       "8   9  1  batch_endpoint_input.csv\n",
       "9  10  1  batch_endpoint_input.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wait for batch job and download results\n",
    "import time\n",
    "\n",
    "job_name = job.name\n",
    "wait_seconds = int(os.getenv('BATCH_WAIT_SECONDS', '600'))\n",
    "poll_seconds = int(os.getenv('BATCH_POLL_SECONDS', '15'))\n",
    "\n",
    "start = time.time()\n",
    "while True:\n",
    "    job_status = ml_client.jobs.get(job_name)\n",
    "    status = job_status.status\n",
    "    print(f'Batch job status: {status}')\n",
    "    \n",
    "    if status in {'Completed', 'Failed', 'Canceled'}:\n",
    "        break\n",
    "    if time.time() - start > wait_seconds:\n",
    "        print('Job still running. Re-run this cell later to check status.')\n",
    "        break\n",
    "    time.sleep(poll_seconds)\n",
    "\n",
    "if status == 'Completed':\n",
    "    # Download the output\n",
    "    output_dir = Path('batch_endpoint_outputs') / job_name\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    ml_client.jobs.download(name=job_name, download_path=str(output_dir), output_name='score')\n",
    "    print(f'Downloaded results to: {output_dir}')\n",
    "    \n",
    "    # Find and display the predictions file\n",
    "    for pred_file in output_dir.rglob('predictions.csv'):\n",
    "        preds_df = pd.read_csv(pred_file)\n",
    "        print(f'\\\\nPredictions from {pred_file}:')\n",
    "        display(preds_df.head(10))\n",
    "        break\n",
    "else:\n",
    "    print(f'Job ended with status: {status}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e4af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get batch endpoint details and scoring URI\n",
    "endpoint_info = ml_client.batch_endpoints.get(batch_endpoint_name)\n",
    "\n",
    "print('=== Batch Endpoint Details ===')\n",
    "print(f'Name: {endpoint_info.name}')\n",
    "print(f'Scoring URI: {endpoint_info.scoring_uri}')\n",
    "print(f'Swagger URI: {endpoint_info.openapi_uri}')\n",
    "print(f'Default deployment: {endpoint_info.defaults.deployment_name}')\n",
    "print(f'\\\\nStudio URL: https://ml.azure.com/batchEndpoints/{batch_endpoint_name}?wsid=/subscriptions/{SUBSCRIPTION_ID}/resourcegroups/{RESOURCE_GROUP}/workspaces/{WORKSPACE_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6858046f",
   "metadata": {},
   "source": [
    "## Optional: Real-time serving (Managed Online Endpoint)\n",
    "This section deploys a **managed online endpoint** (real-time serving). It can take several minutes and requires quota for the chosen VM size.\n",
    "\n",
    "If you want the workshop goal of **MLflow tracking + model registry + batch scoring**, you can skip this section and use the batch scoring section above instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9aad4515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint spam-clf-de533f51 exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint created: spam-clf-de533f51\n",
      "Auth mode: aml_token\n",
      ".........................................................................................................................................................................................."
     ]
    },
    {
     "ename": "HttpResponseError",
     "evalue": "(BadArgument) User container has crashed or terminated: Liveness probe failed: HTTP probe failed with statuscode: 502. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready\nCode: BadArgument\nMessage: User container has crashed or terminated: Liveness probe failed: HTTP probe failed with statuscode: 502. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationFailed\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Lib\\site-packages\\azure\\core\\polling\\base_polling.py:950\u001b[39m, in \u001b[36mLROBasePolling.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m950\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m BadStatus \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Lib\\site-packages\\azure\\core\\polling\\base_polling.py:982\u001b[39m, in \u001b[36mLROBasePolling._poll\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _failed(\u001b[38;5;28mself\u001b[39m.status()):\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OperationFailed(\u001b[33m\"\u001b[39m\u001b[33mOperation failed or canceled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    984\u001b[39m final_get_url = \u001b[38;5;28mself\u001b[39m._operation.get_final_get_url(\u001b[38;5;28mself\u001b[39m._pipeline_response)\n",
      "\u001b[31mOperationFailed\u001b[39m: Operation failed or canceled",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHttpResponseError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mAuth mode:\u001b[39m\u001b[33m'\u001b[39m, endpoint_auth_mode)\n\u001b[32m     20\u001b[39m deployment = ManagedOnlineDeployment(\n\u001b[32m     21\u001b[39m     name=\u001b[33m'\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     22\u001b[39m     endpoint_name=endpoint_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     instance_count=\u001b[38;5;28mint\u001b[39m(os.getenv(\u001b[33m'\u001b[39m\u001b[33mAML_INSTANCE_COUNT\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m1\u001b[39m\u001b[33m'\u001b[39m)),\n\u001b[32m     26\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mml_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43monline_deployments\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin_create_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeployment\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m endpoint = ml_client.online_endpoints.get(endpoint_name)\n\u001b[32m     31\u001b[39m endpoint.traffic = {\u001b[33m'\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m100\u001b[39m}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Lib\\site-packages\\azure\\core\\polling\\_poller.py:323\u001b[39m, in \u001b[36mLROPoller.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> PollingReturnType_co:\n\u001b[32m    315\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the result of the long running operation, or\u001b[39;00m\n\u001b[32m    316\u001b[39m \u001b[33;03m    the result available after the specified timeout.\u001b[39;00m\n\u001b[32m    317\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    321\u001b[39m \u001b[33;03m    :raises ~azure.core.exceptions.HttpResponseError: Server problem with the query.\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._polling_method.resource()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:119\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Lib\\site-packages\\azure\\core\\polling\\_poller.py:342\u001b[39m, in \u001b[36mLROPoller.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    338\u001b[39m \u001b[38;5;28mself\u001b[39m._thread.join(timeout=timeout)\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    340\u001b[39m     \u001b[38;5;66;03m# Let's handle possible None in forgiveness here\u001b[39;00m\n\u001b[32m    341\u001b[39m     \u001b[38;5;66;03m# https://github.com/python/mypy/issues/8165\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# Was None\u001b[39;00m\n\u001b[32m    344\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Lib\\site-packages\\azure\\core\\polling\\_poller.py:247\u001b[39m, in \u001b[36mLROPoller._start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Start the long running operation.\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[33;03mOn completion, runs any callbacks.\u001b[39;00m\n\u001b[32m    245\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_polling_method\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m AzureError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error.continuation_token:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Lib\\site-packages\\azure\\core\\polling\\base_polling.py:965\u001b[39m, in \u001b[36mLROBasePolling.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    958\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(\n\u001b[32m    959\u001b[39m         response=\u001b[38;5;28mself\u001b[39m._pipeline_response.http_response,\n\u001b[32m    960\u001b[39m         message=\u001b[38;5;28mstr\u001b[39m(err),\n\u001b[32m    961\u001b[39m         error=err,\n\u001b[32m    962\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailed \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response=\u001b[38;5;28mself\u001b[39m._pipeline_response.http_response, error=err) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mHttpResponseError\u001b[39m: (BadArgument) User container has crashed or terminated: Liveness probe failed: HTTP probe failed with statuscode: 502. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready\nCode: BadArgument\nMessage: User container has crashed or terminated: Liveness probe failed: HTTP probe failed with statuscode: 502. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready"
     ]
    }
   ],
   "source": [
    "# Create an endpoint name that won't collide across attendees\n",
    "endpoint_name = os.getenv('AML_ENDPOINT_NAME', f'spam-clf-{uuid.uuid4().hex[:8]}')\n",
    "\n",
    "# In locked-down environments, prefer AAD token auth over key auth.\n",
    "# - 'aml_token' uses Azure AD auth (recommended)\n",
    "# - 'key' uses endpoint keys (works in many labs, but may be restricted by policy)\n",
    "endpoint_auth_mode = os.getenv('AML_ENDPOINT_AUTH_MODE', 'aml_token').strip()\n",
    "\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=endpoint_name,\n",
    "    description='Spam classification endpoint (workshop)',\n",
    "    auth_mode=endpoint_auth_mode,\n",
    "    tags={'environment': 'workshop', 'use_case': 'spam_detection'},\n",
    ")\n",
    "\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "print('Endpoint created:', endpoint_name)\n",
    "print('Auth mode:', endpoint_auth_mode)\n",
    "\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name='blue',\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=f'azureml:{registered_model.name}:{registered_model.version}',\n",
    "    instance_type=os.getenv('AML_INSTANCE_TYPE', 'Standard_DS3_v2'),\n",
    "    instance_count=int(os.getenv('AML_INSTANCE_COUNT', '1')),\n",
    ")\n",
    "\n",
    "ml_client.online_deployments.begin_create_or_update(deployment).result()\n",
    "\n",
    "endpoint = ml_client.online_endpoints.get(endpoint_name)\n",
    "endpoint.traffic = {'blue': 100}\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "\n",
    "print('Deployment complete; traffic set to 100%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e16b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint spam-clf-de533f51 exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating deployment \"green\" with numpy<2.0 environment...\n",
      "........................................................................................................................................................................................."
     ]
    },
    {
     "ename": "HttpResponseError",
     "evalue": "(BadArgument) User container has crashed or terminated. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready\nCode: BadArgument\nMessage: User container has crashed or terminated. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationFailed\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Lib\\site-packages\\azure\\core\\polling\\base_polling.py:950\u001b[39m, in \u001b[36mLROBasePolling.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m950\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m BadStatus \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Lib\\site-packages\\azure\\core\\polling\\base_polling.py:982\u001b[39m, in \u001b[36mLROBasePolling._poll\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _failed(\u001b[38;5;28mself\u001b[39m.status()):\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OperationFailed(\u001b[33m\"\u001b[39m\u001b[33mOperation failed or canceled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    984\u001b[39m final_get_url = \u001b[38;5;28mself\u001b[39m._operation.get_final_get_url(\u001b[38;5;28mself\u001b[39m._pipeline_response)\n",
      "\u001b[31mOperationFailed\u001b[39m: Operation failed or canceled",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHttpResponseError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     29\u001b[39m deployment_green = ManagedOnlineDeployment(\n\u001b[32m     30\u001b[39m     name=\u001b[33m'\u001b[39m\u001b[33mgreen\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     31\u001b[39m     endpoint_name=endpoint_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     instance_count=\u001b[32m1\u001b[39m,\n\u001b[32m     36\u001b[39m )\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCreating deployment \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgreen\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m with numpy<2.0 environment...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[43mml_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43monline_deployments\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin_create_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeployment_green\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Set traffic to green\u001b[39;00m\n\u001b[32m     42\u001b[39m endpoint = ml_client.online_endpoints.get(endpoint_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Lib\\site-packages\\azure\\core\\polling\\_poller.py:323\u001b[39m, in \u001b[36mLROPoller.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> PollingReturnType_co:\n\u001b[32m    315\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the result of the long running operation, or\u001b[39;00m\n\u001b[32m    316\u001b[39m \u001b[33;03m    the result available after the specified timeout.\u001b[39;00m\n\u001b[32m    317\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    321\u001b[39m \u001b[33;03m    :raises ~azure.core.exceptions.HttpResponseError: Server problem with the query.\u001b[39;00m\n\u001b[32m    322\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._polling_method.resource()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:119\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Lib\\site-packages\\azure\\core\\polling\\_poller.py:342\u001b[39m, in \u001b[36mLROPoller.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    338\u001b[39m \u001b[38;5;28mself\u001b[39m._thread.join(timeout=timeout)\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    340\u001b[39m     \u001b[38;5;66;03m# Let's handle possible None in forgiveness here\u001b[39;00m\n\u001b[32m    341\u001b[39m     \u001b[38;5;66;03m# https://github.com/python/mypy/issues/8165\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# Was None\u001b[39;00m\n\u001b[32m    344\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Lib\\site-packages\\azure\\core\\polling\\_poller.py:247\u001b[39m, in \u001b[36mLROPoller._start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Start the long running operation.\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[33;03mOn completion, runs any callbacks.\u001b[39;00m\n\u001b[32m    245\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_polling_method\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m AzureError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error.continuation_token:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ritwickdutta\\OneDrive - Microsoft\\Documents\\DND MLOps Demo\\.venv311\\Lib\\site-packages\\azure\\core\\polling\\base_polling.py:965\u001b[39m, in \u001b[36mLROBasePolling.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    958\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(\n\u001b[32m    959\u001b[39m         response=\u001b[38;5;28mself\u001b[39m._pipeline_response.http_response,\n\u001b[32m    960\u001b[39m         message=\u001b[38;5;28mstr\u001b[39m(err),\n\u001b[32m    961\u001b[39m         error=err,\n\u001b[32m    962\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailed \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response=\u001b[38;5;28mself\u001b[39m._pipeline_response.http_response, error=err) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mHttpResponseError\u001b[39m: (BadArgument) User container has crashed or terminated. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready\nCode: BadArgument\nMessage: User container has crashed or terminated. Please see troubleshooting guide, available here: https://aka.ms/oe-tsg#error-resourcenotready"
     ]
    }
   ],
   "source": [
    "# Deploy Managed Online Endpoint (uses the fixed model with numpy<2.0)\n",
    "import uuid\n",
    "\n",
    "# Create a unique endpoint name\n",
    "endpoint_name = os.getenv('AML_ENDPOINT_NAME', f'spam-clf-{uuid.uuid4().hex[:8]}')\n",
    "\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=endpoint_name,\n",
    "    description='Spam classification endpoint (workshop)',\n",
    "    auth_mode='key',  # 'key' or 'aml_token'\n",
    "    tags={'environment': 'workshop', 'use_case': 'spam_detection'},\n",
    ")\n",
    "\n",
    "print(f'Creating endpoint: {endpoint_name}')\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "print(f'Endpoint created!')\n",
    "\n",
    "# Deploy the model (MLflow model with numpy<2.0 will auto-generate compatible environment)\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name='blue',\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=f'azureml:{registered_model.name}:{registered_model.version}',\n",
    "    instance_type='Standard_DS3_v2',\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "print(f'Creating deployment (this may take 5-10 minutes)...')\n",
    "ml_client.online_deployments.begin_create_or_update(deployment).result()\n",
    "\n",
    "# Set traffic\n",
    "endpoint = ml_client.online_endpoints.get(endpoint_name)\n",
    "endpoint.traffic = {'blue': 100}\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "\n",
    "print(f'Deployment complete!')\n",
    "print(f'Endpoint: {endpoint_name}')\n",
    "print(f'Scoring URI: {endpoint.scoring_uri}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3ae55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the endpoint with a few rows\n",
    "test_samples = X_test.head(5).to_dict(orient='split')\n",
    "request_json = json.dumps({\n",
    "    'input_data': {\n",
    "        'columns': test_samples['columns'],\n",
    "        'data': test_samples['data'],\n",
    "    }\n",
    "})\n",
    "\n",
    "response = ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=endpoint_name,\n",
    "    deployment_name='blue',\n",
    "    request_file=None,\n",
    "    request_json=request_json,\n",
    ")\n",
    "\n",
    "print('Raw response:')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6347aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Studio link\n",
    "studio_url = (\n",
    "    f'https://ml.azure.com/experiments/{experiment_name}'\n",
    "    f'?wsid=/subscriptions/{SUBSCRIPTION_ID}/resourceGroups/{RESOURCE_GROUP}'\n",
    "    f'/providers/Microsoft.MachineLearningServices/workspaces/{WORKSPACE_NAME}'\n",
    ")\n",
    "print('Open in Azure ML Studio:')\n",
    "print(studio_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e3619d",
   "metadata": {},
   "source": [
    "## Cleanup (recommended)\n",
    "If you deployed an endpoint, delete it to avoid ongoing cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699bbbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete the endpoint\n",
    "# ml_client.online_endpoints.begin_delete(name=endpoint_name).result()\n",
    "# print('Deleted endpoint:', endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3782ed",
   "metadata": {},
   "source": [
    "# MLOps Hands-On Lab: Azure ML + MLflow Integration\n",
    "\n",
    "This notebook demonstrates the core MLOps concepts using Azure ML with MLflow tracking.\n",
    "\n",
    "## Prerequisites\n",
    "- Azure subscription with ML workspace\n",
    "- Python environment with required packages\n",
    "\n",
    "## Topics Covered\n",
    "1. Setting up MLflow tracking with Azure ML\n",
    "2. Training a model with experiment tracking\n",
    "3. Registering models\n",
    "4. Deploying to managed endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d8d6e1",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd95662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install azure-ai-ml mlflow azureml-mlflow scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82024c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "print(\"Packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd33a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure ML Configuration\n",
    "# Update these values for your environment\n",
    "\n",
    "SUBSCRIPTION_ID = \"<your-subscription-id>\"  # TODO: Update\n",
    "RESOURCE_GROUP = \"rg-dnd-mlops-demo\"\n",
    "WORKSPACE_NAME = \"mlw-dnd-mlops-demo\"\n",
    "\n",
    "# Authenticate\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "# Initialize ML Client\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=SUBSCRIPTION_ID,\n",
    "    resource_group_name=RESOURCE_GROUP,\n",
    "    workspace_name=WORKSPACE_NAME,\n",
    ")\n",
    "\n",
    "print(f\"Connected to workspace: {ml_client.workspace_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8fc383",
   "metadata": {},
   "source": [
    "## 2. Configure MLflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67233853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Azure ML tracking URI\n",
    "tracking_uri = ml_client.workspaces.get(WORKSPACE_NAME).mlflow_tracking_uri\n",
    "\n",
    "# Set MLflow tracking URI\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "print(f\"MLflow tracking URI: {tracking_uri}\")\n",
    "\n",
    "# Set experiment\n",
    "experiment_name = \"mlops-hackathon-demo\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"Experiment: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6fd02f",
   "metadata": {},
   "source": [
    "## 3. Load Real-World Dataset\n",
    "\n",
    "We'll use the **UCI Spambase Dataset** - a classic email spam classification dataset.\n",
    "\n",
    "- **Source**: UCI Machine Learning Repository / OpenML\n",
    "- **Task**: Classify emails as spam (1) or not spam (0)\n",
    "- **Features**: 57 attributes including word frequencies, character frequencies, and capital letter statistics\n",
    "- **Samples**: 4,601 emails\n",
    "\n",
    "This is a realistic dataset used for spam/fraud detection demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4284450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UCI Spambase Dataset (Email Spam Classification)\n",
    "# Source: https://archive.ics.uci.edu/ml/datasets/spambase\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "print(\"Loading Spambase dataset from OpenML...\")\n",
    "\n",
    "# Fetch the spambase dataset (ID: 44)\n",
    "spambase = fetch_openml(data_id=44, as_frame=True, parser='auto')\n",
    "\n",
    "data = spambase.frame\n",
    "\n",
    "# Rename target column for clarity\n",
    "data = data.rename(columns={'class': 'is_spam'})\n",
    "data['is_spam'] = data['is_spam'].astype(int)\n",
    "\n",
    "# Display dataset info\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"  Not Spam (0): {(data['is_spam'] == 0).sum()} ({(data['is_spam'] == 0).mean()*100:.1f}%)\")\n",
    "print(f\"  Spam (1): {(data['is_spam'] == 1).sum()} ({(data['is_spam'] == 1).mean()*100:.1f}%)\")\n",
    "\n",
    "# Show some feature names (word frequencies)\n",
    "feature_names = spambase.feature_names[:10]\n",
    "print(f\"\\nSample features: {feature_names}\")\n",
    "print(\"(Features represent word/character frequencies in emails)\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da05db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = data.drop('is_spam', axis=1)\n",
    "y = data['is_spam']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f9eb36",
   "metadata": {},
   "source": [
    "## 4. Train Model with MLflow Tracking\n",
    "\n",
    "This demonstrates proper experiment tracking with:\n",
    "- Parameter logging\n",
    "- Metric logging\n",
    "- Model artifact logging\n",
    "- Input signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf5ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models import infer_signature\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Hyperparameters\n",
    "params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"min_samples_leaf\": 2,\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"spam-classifier-rf\") as run:\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param(\"training_samples\", len(X_train))\n",
    "    mlflow.log_param(\"dataset\", \"UCI Spambase\")\n",
    "    mlflow.log_param(\"num_features\", X_train.shape[1])\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred),\n",
    "        \"recall\": recall_score(y_test, y_pred),\n",
    "        \"f1_score\": f1_score(y_test, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_pred_proba),\n",
    "    }\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    # Log feature importance (top 20)\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    feature_importance.to_csv(\"feature_importance.csv\", index=False)\n",
    "    mlflow.log_artifact(\"feature_importance.csv\")\n",
    "    \n",
    "    # Infer model signature\n",
    "    signature = infer_signature(X_train, model.predict(X_train))\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(\n",
    "        model,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        registered_model_name=\"spam-classifier\",\n",
    "    )\n",
    "    \n",
    "    print(f\"Run ID: {run.info.run_id}\")\n",
    "    print(f\"\\nMetrics:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n",
    "    print(f\"\\nTop 10 Important Features:\")\n",
    "    print(feature_importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c6bda7",
   "metadata": {},
   "source": [
    "## 5. Register Model in Azure ML Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ece03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# Get the model URI from MLflow\n",
    "model_uri = f\"runs:/{run.info.run_id}/model\"\n",
    "\n",
    "# Register with governance metadata\n",
    "registered_model = ml_client.models.create_or_update(\n",
    "    Model(\n",
    "        path=model_uri,\n",
    "        name=\"spam-classifier\",\n",
    "        type=AssetTypes.MLFLOW_MODEL,\n",
    "        description=\"Email spam classifier trained on UCI Spambase dataset\",\n",
    "        tags={\n",
    "            \"author\": \"mlops-team\",\n",
    "            \"use_case\": \"spam_detection\",\n",
    "            \"dataset\": \"UCI Spambase\",\n",
    "            \"framework\": \"sklearn\",\n",
    "            \"algorithm\": \"RandomForest\",\n",
    "        },\n",
    "        properties={\n",
    "            \"accuracy\": str(round(metrics['accuracy'], 4)),\n",
    "            \"precision\": str(round(metrics['precision'], 4)),\n",
    "            \"recall\": str(round(metrics['recall'], 4)),\n",
    "            \"f1_score\": str(round(metrics['f1_score'], 4)),\n",
    "            \"roc_auc\": str(round(metrics['roc_auc'], 4)),\n",
    "        },\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Model registered: {registered_model.name}:{registered_model.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c3802d",
   "metadata": {},
   "source": [
    "## 6. Deploy to Managed Online Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c35adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    ")\n",
    "\n",
    "# Create endpoint\n",
    "endpoint_name = \"spam-classifier-endpoint\"\n",
    "\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=endpoint_name,\n",
    "    description=\"Spam classification endpoint\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\"environment\": \"demo\", \"use_case\": \"spam_detection\"},\n",
    ")\n",
    "\n",
    "# Create or update endpoint\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "print(f\"Endpoint created: {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eff1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deployment\n",
    "deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    model=f\"azureml:{registered_model.name}:{registered_model.version}\",\n",
    "    instance_type=\"Standard_DS3_v2\",\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "# Create deployment (this may take several minutes)\n",
    "ml_client.online_deployments.begin_create_or_update(deployment).result()\n",
    "\n",
    "# Set traffic to 100%\n",
    "endpoint.traffic = {\"blue\": 100}\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "\n",
    "print(f\"Deployment created and traffic set to 100%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06a42a2",
   "metadata": {},
   "source": [
    "## 7. Test the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95249c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Prepare test data\n",
    "test_samples = X_test.head(5).to_dict(orient='split')\n",
    "\n",
    "request_json = json.dumps({\n",
    "    \"input_data\": {\n",
    "        \"columns\": test_samples['columns'],\n",
    "        \"data\": test_samples['data']\n",
    "    }\n",
    "})\n",
    "\n",
    "# Invoke endpoint\n",
    "response = ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=endpoint_name,\n",
    "    request_file=None,\n",
    "    deployment_name=\"blue\",\n",
    "    request_json=request_json,\n",
    ")\n",
    "\n",
    "print(\"Predictions:\")\n",
    "print(json.loads(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcda32b",
   "metadata": {},
   "source": [
    "## 8. View Experiment in Azure ML Studio\n",
    "\n",
    "Navigate to Azure ML Studio to see:\n",
    "- Experiment runs\n",
    "- Metrics comparison\n",
    "- Model registry\n",
    "- Endpoint monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f845402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get workspace URL\n",
    "workspace = ml_client.workspaces.get(WORKSPACE_NAME)\n",
    "studio_url = f\"https://ml.azure.com/experiments/{experiment_name}?wsid=/subscriptions/{SUBSCRIPTION_ID}/resourceGroups/{RESOURCE_GROUP}/providers/Microsoft.MachineLearningServices/workspaces/{WORKSPACE_NAME}\"\n",
    "\n",
    "print(f\"View experiment in Azure ML Studio:\")\n",
    "print(studio_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851e2869",
   "metadata": {},
   "source": [
    "## 9. Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf234dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete resources\n",
    "# ml_client.online_endpoints.begin_delete(name=endpoint_name).result()\n",
    "# print(f\"Endpoint {endpoint_name} deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8adda70",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **MLflow Integration**: Azure ML provides native MLflow tracking URI\n",
    "2. **Experiment Tracking**: All parameters, metrics, and artifacts are versioned\n",
    "3. **Model Registry**: Centralized registry with governance metadata\n",
    "4. **Managed Endpoints**: Easy deployment with built-in scaling and monitoring\n",
    "\n",
    "## Next Steps\n",
    "- Add automated retraining pipeline\n",
    "- Enable model monitoring for data drift\n",
    "- Set up CI/CD with GitHub Actions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
